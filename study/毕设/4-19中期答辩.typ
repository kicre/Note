#import "../../tem/beamer.typ": beamer
#show: beamer.with(
  title: "åŸºäº SAM å¤§æ¨¡å‹çš„è‚è„è‚¿ç˜¤åˆ†å‰²è½¯ä»¶å¼€å‘",
  subtitle: "4-19 ä¸­æœŸç­”è¾©",
  author: "ç­”è¾©äººï¼šç‹æº                     æŒ‡å¯¼è€å¸ˆï¼šåˆ˜ç¨",
  date: "è´¨é‡æŠ€æœ¯ç›‘ç£å­¦é™¢   2020çº§æµ‹æ§æ™®é€šç­  2024-04-19",
)

= é¡¹ç›®ä»‹ç»

== èƒŒæ™¯

=== å‡†ç¡®åˆ†å‰²è‚è„è‚¿ç˜¤åœ¨åŒ»å­¦å›¾åƒé¢†åŸŸçš„é‡è¦æ€§

è‚è„è‚¿ç˜¤ä½œä¸ºå¸¸è§çš„æ¶æ€§è‚¿ç˜¤ä¹‹ä¸€ï¼Œå…¶æ—©æœŸå‘ç°å’Œæ²»ç–—å¯¹æé«˜æ‚£è€…ç”Ÿå­˜ç‡è‡³å…³é‡è¦ã€‚ä¼˜ç§€çš„è‚è„è‚¿ç˜¤åˆ†å‰²è½¯ä»¶èƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿæä¾›æ›´ç²¾ç¡®çš„åˆ†å‰²ç»“æœï¼Œå‡å°‘å·¥ä½œé‡ï¼Œæé«˜æ‚£è€…çš„å­˜æ´»ç‡ã€‚

=== å·¥ç¨‹èƒŒæ™¯

æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨å›¾åƒåˆ†å‰²é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œç‰¹åˆ«æ˜¯U-Netã€V-Netç­‰æ¨¡å‹ç›®å‰åœ¨è‚è„è‚¿ç˜¤åˆ†å‰²ä¸Šçš„åº”ç”¨è¾ƒä¸ºå¹¿æ³›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä¸”è¿ç§»èƒ½åŠ›æœ‰é™ã€‚

#align(
  center + horizon, 
  figure(
    image(width: 20%, "U-net.png"),
    caption:[U-net]
  )
)

= ç ”ç©¶æ–¹æ¡ˆ

== ä½¿ç”¨ SAM æ¨¡å‹è¿›è¡Œè‚è„è‚¿ç˜¤å›¾åƒåˆ†å‰²

SAM æ˜¯ä¸€ç§åŸºäºVision Transformeræ¶æ„çš„å›¾åƒåˆ†å‰²æ¨¡å‹ã€‚å®ƒé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒå­¦ä¼šäº†ç†è§£å’Œå¤„ç†å„ç§å›¾åƒç‰¹å¾ã€‚SAMæ¨¡å‹çš„ä¸€ä¸ªå…³é”®ç‰¹ç‚¹æ˜¯å®ƒçš„é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰å­¦ä¹ èƒ½åŠ›ï¼Œå³æ¨¡å‹èƒ½å¤Ÿåœ¨æ²¡æœ‰ç›´æ¥åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç†è§£ç”¨æˆ·çš„æç¤ºï¼ˆå¦‚æ–‡æœ¬æè¿°ã€ç‚¹å‡»æˆ–æ¡†é€‰ï¼‰æ¥æ‰§è¡Œåˆ†å‰²ä»»åŠ¡ã€‚

== SAM çš„ä¼˜åŠ¿

- å¼ºå¤§çš„ç‰¹å¾å­¦ä¹ ï¼šSAMåœ¨å¤§é‡è‡ªç„¶å›¾åƒä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ åˆ°äº†ä¸°å¯Œçš„è§†è§‰ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯¹äºç†è§£åŒ»å­¦å›¾åƒä¸­çš„è‚¿ç˜¤åŒºåŸŸéå¸¸æœ‰ç”¨ã€‚

- æ³›åŒ–èƒ½åŠ›ï¼šSAMèƒ½å¤Ÿæ³›åŒ–åˆ°æ–°çš„æ•°æ®é›†å’Œä»»åŠ¡ä¸Šï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥é€‚åº”ä¸åŒçš„åŒ»å­¦å›¾åƒå’Œè‚¿ç˜¤ç±»å‹ã€‚

- ç«¯åˆ°ç«¯åˆ†å‰²ï¼šSAMå¯ä»¥ç›´æ¥ä»åŸå§‹å›¾åƒè¾“å‡ºåˆ†å‰²æ©ç ï¼Œæ— éœ€å¤æ‚çš„é¢„å¤„ç†æˆ–åå¤„ç†æ­¥éª¤ã€‚

- æ˜“äºé›†æˆï¼šSAM çš„ API å’Œå·¥å…·è®¾è®¡ä½¿å¾—å®ƒå®¹æ˜“é›†æˆåˆ°ç°æœ‰çš„åŒ»ç–—å½±åƒåˆ†ææµç¨‹ä¸­ï¼Œä¸ºç ”ç©¶è°ƒè¯•å’Œè½¯ä»¶å¼€å‘æä¾›äº†ä¾¿åˆ©ã€‚

= é¡¹ç›®è¿›å±•

== æ•°æ®é¢„å¤„ç†


```py
lower_bound = -500
upper_bound = 1000
image_data_pre = np.clip(image_data, lower_bound, upper_bound)
image_data_pre = (image_data_pre - np.min(image_data_pre))/(np.max(image_data_pre)-np.min(image_data_pre))*255.0
image_data_pre[image_data==0] = 0
image_data_pre = np.uint8(image_data_pre)
```

=== å°†åŒ»å­¦å›¾åƒå¸¸ç”¨ `.nii` æ ¼å¼è½¬åŒ–ä¸º NPY å›¾åƒæ ¼å¼

```py
import os
import SimpleITK as sitk
import numpy as np

# è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
input_folder = 'input_folder'
output_folder = 'output_folder'

# è·å–è¾“å…¥æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰çš„.nii.gzæ–‡ä»¶
input_files = [f for f in os.listdir(input_folder) if f.endswith('.nii.gz')]

# éå†æ¯ä¸ª.nii.gzæ–‡ä»¶å¹¶è½¬æ¢ä¸º.npzæ ¼å¼
for file_name in input_files:
    # è¯»å–.nii.gzæ–‡ä»¶
    image = sitk.ReadImage(os.path.join(input_folder, file_name))
    image_array = sitk.GetArrayFromImage(image)
    
    # ä¿å­˜ä¸º.npzæ ¼å¼
    np.savez_compressed(os.path.join(output_folder, file_name.replace('.nii.gz', '.npz')), image=image_array)

print("Conversion completed.")
```

=== å°†æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒé›†ä¸æµ‹è¯•é›†

```py
import numpy as np

# å‡è®¾dataæ˜¯ä½ çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬ç‰¹å¾å’Œæ ‡ç­¾
data = np.random.randn(100, 10)
labels = np.random.randint(0, 2, size=100)

# å®šä¹‰è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ¯”ä¾‹
train_ratio = 0.8
test_ratio = 1 - train_ratio

# éšæœºæ‰“ä¹±æ•°æ®é›†çš„ç´¢å¼•
indices = np.random.permutation(data.shape[0])

# è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ·æœ¬æ•°é‡
train_samples = int(data.shape[0] * train_ratio)
test_samples = data.shape[0] - train_samples

# æ ¹æ®ç´¢å¼•åˆ†å‰²æ•°æ®é›†
train_data = data[indices[:train_samples]]
train_labels = labels[indices[:train_samples]]
test_data = data[indices[train_samples:]]
test_labels = labels[indices[train_samples:]]

print("è®­ç»ƒé›†æ ·æœ¬æ•°é‡:", train_data.shape[0])
print("æµ‹è¯•é›†æ ·æœ¬æ•°é‡:", test_data.shape[0])
```

== æ— å¾®è°ƒè¿è¡Œ SAM å¯¹å›¾åƒåˆ†å‰²å¤„ç†ç»“æœ

#align(
  center + horizon, 
  figure(
    image(width: 35%, "mask3.jpg"),
    caption:[Mask 3 score:0.878]
  )
)

== æ¨¡å‹è®­ç»ƒ

=== è®¾ç½®ä¼˜åŒ–æŸå¤±å‡½æ•°

ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ä¼˜åŒ–æ©ç å™¨éƒ¨åˆ†ï¼Œè®¾ç½® Dice+Cross Entropy Loss ä½œä¸ºæŸå¤±å‡½æ•°ã€‚

```py
optimizer = torch.optim.Adam(sam_model.mask_decoder.parameters(), lr=args.lr, weight_decay=args.weight_decay)
seg_loss = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')
```

=== è®­ç»ƒæ¨¡å‹

å¾ªç¯è®­ç»ƒï¼Œé€šè¿‡ SAM æ¨¡å‹ çš„ æ©ç è§£ç å™¨è·å–é¢„æµ‹ç»“æœï¼Œè®¡ç®—æŸå¤±ï¼Œä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°ï¼Œæœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚

```py
for epoch in range(num_epochs):
    for step, (image_embedding, gt2D, boxes) in enumerate(tqdm(train_dataloader)):
        # è·å–æ¨¡å‹è¾“å‡º
        low_res_masks, iou_predictions = sam_model.mask_decoder(
            image_embeddings=image_embedding.to(device),
            image_pe=sam_model.prompt_encoder.get_dense_pe(),
            sparse_prompt_embeddings=sparse_embeddings,
            dense_prompt_embeddings=dense_embeddings,
            multimask_output=False,
          )

        # è®¡ç®—æŸå¤±å¹¶ä¼˜åŒ–æ¨¡å‹
        loss = seg_loss(low_res_masks, gt2D.to(device))
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

= åç»­å·¥ä½œ

=== ğŸŒŸå¯¹æ¨¡å‹è®­ç»ƒç»“æœè¯„ä¼°

- è‚¿ç˜¤åˆ†å‰²çš„ç²¾ç¡®åº¦ã€å¬å›ç‡å’Œ Dice ç³»æ•°ç­‰æ€§èƒ½æŒ‡æ ‡ã€‚

- SAM æ¨¡å‹ç»“æœä¸å…¶ä»–åˆ†å‰²æ¨¡å‹çš„è§†è§‰æ¯”è¾ƒã€‚

- å±•ç¤º SAM å¤§å‹æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§çš„æ¡ˆä¾‹ç ”ç©¶æˆ–å®ä¾‹ã€‚

===  ğŸŒŸå‰ç«¯æ¥å£

- ä¸ºè½¯ä»¶å¼€å‘çš„å‰ç«¯ç•Œé¢ã€‚

- ç•Œé¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç»“æœæ˜¾ç¤ºã€äº¤äº’å·¥å…·å’Œå…¶ä»–åŠŸèƒ½ã€‚

- å®ç°ä¾¿æ·çš„å›¾åƒè¾“å…¥ï¼Œç»“æœæ˜¾ç¤ºæ“ä½œã€‚

- ç”¨æˆ·å‹å¥½çš„è®¾è®¡å’ŒåŒ»ç–—ä¸“ä¸šäººå‘˜çš„æ˜“ç”¨æ€§ã€‚

=== ğŸŒŸè®ºæ–‡æ’°å†™
