---
title: 基于 SAM 模型的肝脏肿瘤分割软件开发
subtitle: 河北大学本科毕业设计
author: 王恺
abstract: |-
  本研究提出了一种基于Segment Anything Model （SAM） 的方法，用于肝脏肿瘤CT图像的自动分割。通过对SAM模型进行微调，并利用交叉熵损失和Dice损失结合的优化策略，我们提高了模型的分割准确性。实验结果表明，微调后的SAM模型在Dice系数、相对绝对体积误差（RAVD）、平均对称表面距离（ASSD）和Hausdorff距离（HD）等多个评估指标上，均显著优于传统方法和其他深度学习方法。该模型不仅能够在少量标注数据的情况下保持高效的分割性能，还展示了较强的泛化能力，适用于其他类型的医学图像分割任务。未来研究将进一步优化模型架构、进行大规模临床验证并提高模型解释性，以期在实际临床应用中发挥更大的作用。
  肝脏是人体内非常重要的实质器官，肝脏疾病严重影响着人体健康，肝癌更是致死率极高的恶性肿瘤之一，精准的肝脏图像分割是医生诊断与治疗过程中的重要参考。由于计算机断层扫描成像（Computed Tomography， CT）具有安全方便、成像速度快、分辨率较高等优点，CT 成像成为常用的检查方式。肝脏和肝肿瘤的 CT 图像具有形态各异、边缘模糊和位置多变等特点，传统上以手动标注实现的 CT 图像分割，不仅耗时耗力而且易出现分割误差。
  因此，基于深度学习实现肝脏和肝肿瘤 CT 图像的全自动化精准分割具有重要的研究意义。
keywords:
  - CT图像
  - SAM
  - 深度学习
  - 肝脏分割
  - 肝脏肿瘤分割
lang: zh-CN
---

# 绪论

## 研究的背景及意义

肝脏肿瘤是全球范围内导致死亡的主要原因之一，计算机断层扫描（CT）是检测和评估肝脏肿瘤的重要影像学方法。为了提高诊断效率和准确性，自动化的图像分割技术应运而生。近年来，深度学习技术在医学图像分割领域取得了显著进展。然而，深度学习方法依赖于大量标注数据进行训练，而医学影像数据的标注成本高昂，需要专业的医学人员参与。Meta AI 提出的 Segment Anything Model （SAM）为肝脏肿瘤自动分割提供了新的可能。

医学影像技术，特别是计算机断层扫描（CT）技术，在现代医疗体系中扮演着至关重要的角色。CT图像能提供关于人体内部结构的详细视图，对于诊断、治疗计划制定以及病情监测等都极为重要。精确的图像分割技术能够帮助医生更好地理解和解析这些图像，从而在疾病诊断和治疗中做出更加精确的决策[@LiuLiangBinGuoNeiWaiTuXiangFenGeJiShuZaiYiLiaoJianKangLingYuYingYongFaZhanTaiShiFenXi2023]。医学影像技术如X射线、CT、MRI以及超声等允许医生非侵入性地查看体内器官的结构和功能。这些技术使得医生能够在疾病的早期阶段就进行诊断，特别是在肿瘤学、心血管疾病和神经系统疾病等领域。例如，通过MRI和CT扫描，可以早期发现和定位癌症肿瘤，大大提高治愈的可能性。精确的医学影像分析不仅有助于疾病的诊断，还能为制定个性化的治疗方案提供依据。例如，在放射治疗计划中，精确的图像分割可以帮助医生确定放射线剂量的精确分布，以最大限度地破坏肿瘤细胞同时保护周围健康组织。定期的医学影像检查可以监控疾病的进展情况，评估治疗效果，及时调整治疗策略[@LiXiaoYanJiaQiangGanAiNeiKeDuiWuJianSheChongShiGanAiNeiKeGuiFanHuaHeGeXingHuaZhenLiaoJueCe]。在手术前进行详细的影像分析可以帮助外科医生规划手术路径，识别并避开关键结构如血管和神经。此外，实时影像引导手术（如超声引导的介入手术）可以提高手术的精确性和安全性，减少手术中的风险。同时，随着精准医疗和个体化治疗策略的发展，医学影像分析在个体化医疗中的作用日益突出。通过分析患者的影像数据，医生可以更好地理解患者的独特生理和病理状态，从而提供更加定制化的治疗方案。医学影像分析还是许多生物医学研究的基础，例如在神经科学、肿瘤学和发育生物学等领域。高质量的影像数据和先进的影像处理技术能够帮助科研人员探索疾病的机制，发现新的治疗目标，以及评估新药物和疗法的效果。

肝脏肿瘤，包括良性和恶性肿瘤，是世界范围内常见的肝脏疾病之一。准确快速地对肝脏肿瘤进行分割，在临床诊断、治疗规划以及手术导航中起着重要作用。肝脏肿瘤的早期诊断和治疗是提高患者生存率的关键[@XingXueXiaSuiShengGanZangEXingZhongLiuWaiKeZhiLiaoDeXianDaiCeLue]。在诊断过程中，肝脏肿瘤的准确分割为医生提供了重要的形态学信息，有助于治疗规划和效果评估。随着医学影像技术，尤其是CT图像的快速发展，获得高质量的肝脏图像变得更加容易，但手动分割仍旧耗时且易受操作者经验的影响。因此，自动化的肝脏肿瘤分割技术在医疗领域的应用至关重要。

肝脏肿瘤分割是一项挑战性工作，因为肝脏肿瘤在早期往往体积较小难以分辨，并且肝脏的形态多变且肿瘤与正常组织的边界往往不清晰。在传统方法中，需要大量的手动标注工作，耗时且费力。而使用 SAM 处理具有明显边界和少量模糊的医学图像时，能够有效提高分割的准确性和效率[@mazurowskiSegmentAnythingModel2023a]。通过利用 SAM 模型的强大功能，开发针对性的肝脏肿瘤分割软件成为可能。

近年来，深度学习在图像处理和计算机视觉领域取得了显著进展，其在医学图像分割任务中展现出了巨大潜力[@JiangShengHuiJiYuShenDuXueXiDeGanZangJiGanZhongLiuCTTuXiangFenGeSuanFaYanJiu]。众多深度学习模型，如卷积神经网络（CNN）、U-Net、V-Net等已经被成功应用于肝脏肿瘤甚至多器官的分割，取得了优异的结果。这些研究不仅提高了分割的准确性，而且大大缩短了处理时间。Segment Anything Model（SAM），作为一种基于深度学习的全新模型架构，已在多个自然图像处理基准上显示出优异的性能。SAM 的引入为医学图像，特别是复杂的肝脏肿瘤分割任务，提供了新的可能性。

SAM 模型是 Meta AI 提出的一个基于 Transformer 的深度学习模型，它是在超过一亿张图像和相应标记的基础之上训练得来，用于执行零样本学习（Zero-shot Learning）中的图像分割任务，它能够通过接收简单的标注提示（如点、框等），自动产生精确的图像分割，这在处理医学图像中的不同器官和病变（如肝脏肿瘤）时，表现出独特的优势[@huangSegmentAnythingModel2024a]。使用SAM 模型应用与医学图像处理具有以下优势：

- 泛化能力强：SAM通过在大量图像上进行预训练，学习了丰富的视觉特征表示，具备强大的泛化能力，能够应对多样的图像分割任务。
- 少样本学习：在具有少量标注数据的情况下，SAM仍然能表现出良好的分割效果，这对于医学影像分析尤其重要，因为高质量的医学标注数据往往难以获得。
- 自适应性强：作为一种自适应的模型，SAM能够根据不同的输入图像和分割任务调整其行为，这使得它在面对肝脏肿瘤这种形态多样、边界模糊的目标时，表现出比传统方法更好的分割精度。

在医学图像分析领域，特别是肝脏肿瘤的精确分割中，选择合适的图像分割算法对于提高诊断准确性和疾病管理至关重要[@PanLuHaiJiYuShenDuXueXiDeNaoBuZhongLiuYiXueTuXiangFenGeMoXingYanJiu2024]。基于SAM大模型的肝脏肿瘤分割软件开发具有重要的临床意义和广阔的应用前景。通过利用SAM模型的高泛化能力和出色的图像处理性能，可以极大地提升肝脏肿瘤的诊断精度，助力医生更有效地制定治疗计划，最终提高患者的生存率。开发此类高效的肝脏肿瘤分割软件不仅能推动医学影像分析技术的进步，也将为全球癌症治疗带来积极的影响。

## 国内外研究现状

医学图像分割的目的是从图像中将目标区域分割出来，获得分割目标的信息。医生通过参考这些实现更完善的诊断及治疗。在过去的几十年里，国内外研究人员为精准分割出腹部图像中的肝脏和肝肿瘤，提出了许多优秀的分 割算法。本文将这些算法主要分为传统方法与机器学习方法进行总结[@chenLearningActiveContour2019]。

### 基于传统方法的肝脏肿瘤分割

基于传统方法的肝脏和肝肿瘤图像分割算法主要包括阈值法[@osuna-encisoComparisonNatureInspired2013]、主动轮廓法[@wangAdaptableActiveContour2019]、区域生长法[@chenLearningActiveContour2019]等。阈值法分割图像主要使用图像中的灰度信息，首先对图像中的像素点进行运算设定 出多个不同的特征阈值，然后根据这些阈值将图像中的像素点进行分类，主要分为感兴趣区域和背景的若干类。尽管该方法中使用了自适应阈值化，不再使用人工选取的方式确定阈值，然而由于肝肿瘤具有边缘不清晰、图像灰度信息分布不均匀的图像特点，仅仅依靠灰度值信息对肝脏肿瘤进行 分割仍然是一个很大的挑战，无法实现对肝脏肿瘤的准确分割。主动轮廓法，一经提出就被广泛应用于图像分割领域。被广泛应用的原因主要是主动轮廓法与阈值法相比，可以获得光滑的闭合曲线。主动轮廓法的基本思想是通过构造能量函数，使初始轮廓曲线随着能量函数的最小值的驱动， 逐渐向待分割物体的边缘靠近，最后分割出目标的真实轮廓。该方法存在的不足是初始轮廓的设定对最终的 分割结果影响较大，倘若初始轮廓在图像的影响下不是全局能量最小的轮廓，就极易陷入局部最优，导致分割效果不稳定且能量函数不收敛。区域生长是一种基于区域的分割方法，，从人工选取的一组种子点出发，不断地将与种子点性质相似的区域的像素组合进来，一直到满足区域生长的终止条件后再停止分割。区域生长法需要手动确定一组能确切代表目标区域的种子像素，既然通过人工选取，那就存在一定的不确定性，选取的种子不同，最后的分割结果就不同，导致模型的鲁棒性较差。

### 基于深度学习的肝脏肿瘤分割

#### 基于卷积对抗神经网络（CNN）的分割方法

CNN是深度学习技术中最早应用于医学图像分割的算法之一，它通过层叠的卷积层来提取图像特征，已成功应用于多种医学图像处理任务[@WangGuoLiYiXueTuXiangTuShenDuXueXiFenGeSuanFaZongShu2022]。然而，尽管CNN在特征提取方面表现出色，但其对训练数据的依赖性较大，需要大量精确标注的数据，这在医学领域往往是一个限制因素。此外，CNN模型的泛化能力受限于训练数据的多样性和质量[@JinHuYongJiYuJuanJiShenJingWangLuoDeShuiShengTongXinXiTongQianDaoJianCeYuXinDaoFenLei]。对数据的训练数据的大量需求增加了其训练开发难度，为该方面的实际应用增加了成本。

#### U-Net 及其变种

U-Net 是为医学图像分割特别设计的网络结构，它通过特有的跳跃连接和上采样策略，有效地保留了图像的细节信息，适合于处理样本量较少的医学图像数据。U-Net 及其变种神经网络模型在肝脏肿瘤等复杂结构的分割任务中表现出良好的性能。然而，U-Net 对图像中的噪声和伪影比较敏感，这可能影响其在实际临床应用中的分割准确性[@ZhangChengChengJiYuJiLianJuanJiShenJingWangLuoDeGanZangZhongLiuFenGeYuJianCeFangFaYanJiu]。

#### 基于 Transformer 的方法（如SAM）

近期，基于 Transformer 的 Segment Anything Model（SAM）展示了其在图像分割任务中的卓越潜力。不同于传统的 CNN 和 U-Net，SAM 采用 Transformer 架构处理图像中的长距离依赖，能够捕获更加丰富的上下文信息。SAM的 一个显著优势是其零样本学习能力，即在未见过的新图像上，仅通过少量的提示（如点或框）就能实现准确的分割。这一优势特性在处理多变的医学图像，尤其是肝脏肿瘤图像时显得尤为重要，因为这些图像常常包含不规则的肿瘤边界和复杂的背景结构。

在最近的研究中，有相关论文表明，SAM在处理带有阴影伪影和不均匀强度分布的超声图像时，能够有效识别并分割出肝脏肿瘤区域[@chenAbilitySegmentingAnything2023a]。此外，Mazurowski 等的 SAM 医学图像分割分析实验研究进一步验证了 SAM 在不同医学成像数据集上的广泛适用性，尤其是在处理肝CT图像时，SAM 显示出较高的 IoU 性能[@mazurowskiSegmentAnythingModel2023a]。

### 结论

总体来说，虽然多种方法各有优势，SAM 方法由于其强大的零样本学习能力和优异的上下文捕获能力，展现了在医学图像，特别是在肝脏肿瘤分割方面的独特优势。未来研究可以进一步探索如何优化 SAM 模型以适应具体的医学图像特征，以及如何将这些高级模型与医学专家的临床经验相结合，从而在提高肝脏肿瘤诊断和治疗的准确性方面发挥重要作用。

## 研究内容及创新点

第一章主要对介绍自动化肝脏肿瘤分割现有的可行方案和及未来发展方向进行了描述。综述了国内外近一段时间肝脏肿瘤等医学图像处理的研究及深度学习等大模型的发展应用，对比其性能指标。之后，讲述了深度学习图像处理的工作原理以及分类。讲解了评估模型的性能指标以及计算方法。

第二章简单介绍研究所用的各项技术原理，包括深度学习，Transformer，pytorch 框架，SAM 模型。

第三章描述试验方法，首先安装模型与搭建微调必需的包，创建配置文件，然后使用数据集进行训练，最后遍历数据集训练，输出损失函数。

第四章选取其他几种领先的分割模型作为比较对象，与本研究模型比较分析，全面评估基于 SAM 大模型的肝脏肿瘤开发软件的性能。

第五章对全文进行总结和展望。

本文的创新之处在于使用了大型自监督学习模型 SAM 开发肝脏肿瘤分割软件，该研究方法的优势体现在以下几个方面：

1. 提高肝脏肿瘤分割的准确性和灵活性：利用SAM模型的强大特征提取能力，可以更准确地识别和分割肝脏中的肿瘤组织，特别是在肿瘤边界模糊或与周围组织对比度低的情况下。

2. 减少对标注数据的依赖：由于SAM模型基于自监督学习，在训练过程中不完全依赖标注数据，通过利用自监督学习，该软件能够利用未标注的医学图像进一步提升模型的性能和泛化能力。

3. 提升分割速度，支持实时应用：针对 SAM 模型的实现进行了微调优化，使得肝脏肿瘤分割软件能够快速处理图像，满足临床环境中对实时或近实时分析的需求。

SAM 模型的提出者 Jim Fan 认为，这是计算机视觉领域的 GPT-3 时刻。GPT-3 是一种强大的自然语言处理模型，通过预训练和微调，能够适应各种语言任务。同样地，SAM模型通过预训练和微调，能够适应各种图像分割任务。这种跨领域的借鉴和启发使得SAM模型在视觉分割领域取得了重大突破。本文对 SAM 的研究开发是在探索和发展新的概念、工具和方法

### 结论

《基于SAM大模型的肝脏肿瘤分割软件开发》通过引入前沿的自监督学习技术，不仅提高了分割的精度和效率，还降低了对标注数据的依赖，提供了一种新的解决方案来解决医学图像分割中的一些长期挑战。这些创新之处使得该软件在医学图像处理领域具有较高的应用价值和推广前景。

## 本章小结

本章主要讲述的是基于 SAM 大模型的肝脏肿瘤分割的研究背景此外，本章简单描述了医学图像分割方法的发展历程以及时代需求，介绍了近几年国内外医学图像分割领域的研究现状，比较了目前医学图像处理的研究成果，介绍了几种重要的分割方法的工作原理以及分类。

# 技术原理学习

## 肝脏肿瘤 CT 图像

计算机断层扫描（Computed Tomography， CT）技术是一种先进的医学成像技术，通过利用X射线和计算机技术生成身体内部详细的横断面图像。CT扫描利用旋转的X射线管和对面的探测器阵列从不同角度获取人体的X射线数据。这些数据被计算机处理，重建出二维切片图像。这些切片图像可以通过计算机系统堆叠组合成三维图像，从而提供详细的内部结构视图以供放射科医生查看图像，以识别疾病或异常。生成的报告发送给主治医生，以便进行进一步治疗决策。如 2.1 所示，左上三图为腹部 CT 扫描 MPR 预览图，右下为 3D 图像预览。

![]（腹部.png）

图 2.1 肝脏 CT 扫描图像

CT 图像的优点有以下几点：

1. **高分辨率**：能够清晰显示细微结构和病变。
2. **快速成像**：现代CT扫描仪能够在几秒钟内完成扫描，适合紧急情况。
3. **多平面成像**：能够生成横断面、冠状面和矢状面图像，提供多角度视图。
4. **三维重建**：通过多个切片图像的组合，生成精确的三维图像。

CT 扫描技术在头部和脑部成像、胸部成像、腹部和盆腔成像、骨骼和关节成像、血管成像等医学领域具有广泛应用，用于评估各类肿瘤等多种身体疾病异常如肝脏肿瘤的治疗。

肝脏肿瘤的分割是医学图像处理中一项具有挑战的任务，CT 图像分割作为一种非侵入性的诊断方法，可以帮助医生更准确地确定肝脏肿瘤的位置、形状和大小，为后续治疗提供重要的参考依据，但肝脏肿瘤的分割面临以下难点。

1. **肿瘤形态多样性**
    肝脏肿瘤的形态、大小和位置具有高度多样性，导致图像中肿瘤区域的外观各异。肿瘤可能是单个的，也可能是多发的，其形状可以是规则的，也可以是非常不规则的。这种多样性增加了分割的难度。

2. **图像噪声和伪影**
    CT 图像中常常存在噪声和伪影，这些干扰信息会影响图像的清晰度和对比度，进而影响肿瘤区域的准确识别和分割。特别是在低剂量 CT 扫描中，噪声问题更加突出。

3. **肝脏结构复杂**
    肝脏内部结构复杂，包含血管、胆管等多种解剖结构，这些结构在 CT 图像中可能与肿瘤区域混淆，增加了分割的难度。此外，肝脏边界与周围器官（如胃、肠、肾）接近，界限模糊，进一步增加了分割任务的复杂性。

4. **肿瘤与正常组织对比度低**
    肿瘤与正常肝脏组织的密度对比度往往较低，特别是一些小肝癌或早期肝癌，难以在 CT 图像中明显区分。这种低对比度使得自动化分割算法难以准确区分肿瘤和正常组织。

5. **患者间差异**
    不同患者的肝脏形态和肿瘤特征存在显著差异，这种个体差异增加了图像分割算法的泛化难度。一种分割方法可能在某些患者图像上表现良好，但在另一些患者图像上效果不佳。

6. **数据标注困难**
    高质量的肝脏肿瘤分割需要大量准确的标注数据，这些标注通常由放射科医生手动完成，耗时费力且容易受主观影响。这限制了训练和验证分割算法所需的数据量和质量。

如上所述，对 CT 图像中的肝脏肿瘤进行分割困难极大，人类极难分辨如图 2.2 的微小肿瘤图像，这些肿瘤几乎肉眼不可见。因此，使用 SAM 大模型的肝脏肿瘤分割方法具有重要意义[@MaJinLinGanZangZhongLiuCTTuXiangShenDuXueXiFenGeFangFaZongShu2020]。

![肝脏肿瘤示意]（肝脏肿瘤示意.png）

图 2.2 肝脏肿瘤 CT 图像示意，从左到右依次为原 CT 图像，肝脏标注，肿瘤标注。

## 深度学习基本原理

深度学习是机器学习的一个分支，基于多层神经网络模拟人脑处理数据的方式[@GuoFengJiYuShenDuJuanJiShenJingWangLuoYaoGanTuXiangMuBiaoJianCeSuanFaYanJiu]。它涵盖从输入层接收数据，通过多个隐藏层处理，到输出层产生结果的过程。每个神经元根据权重和偏差处理输入，并通过激活函数引入非线性，使得模型能处理复杂任务。训练神经网络涉及使用损失函数评估预测误差，并通过反向传播和梯度下降等优化算法调整网络参数，以减少误差。此外，为避免过拟合，常用正则化技术如舍弃法（Dropout）[@WangRuiBoJiYuDropoutZhengZeHuaDeHanYuKuangJiaYuYiJiaoSeShiBie]。深度学习在图像识别、语音处理等领域展示出显著的应用潜力，通过适当的网络设计和算法优化，可以有效从大量数据中学习复杂的规律。深度学习模型能够从大量数据中自动学习到复杂的特征表示，这一点在图像识别、语音识别等任务中尤为显著。

## Pytorch框架

PyTorch 是一个开源的机器学习库，广泛用于计算机视觉和自然语言处理等领域。它由Facebook的人工智能研究团队开发，并得到了包括微软、Salesforce等多家大公司的支持和贡献。PyTorch 是一种强大的深度学习框架，适合从学术研究到商业应用的广泛用途。它的灵活性、用户友好的设计以及强大的社区支持使其成为当前最受欢迎的深度学习框架之一[@maSegmentAnythingMedical]。

- PyTorch 以其动态计算图（Dynamic Computation Graphs），即“define-by-run”方法论而闻名。这种方式让每一次的网络操作都可以动态地改变计算图，提供了极高的灵活性和直观操作方式，使得模型设计和调试更为简单直接。
- PyTorch 提供了丰富的API，这些API设计直观并易于理解，极大地简化了深度学习模型的开发过程。它支持大量的预定义层，如全连接层、卷积层、池化层等，以及多种损失函数和优化器，这使得构建复杂的神经网络变得更加容易。
- PyTorch 拥有一个活跃的社区，提供大量的教程、工具和预训练模型，这些资源可以帮助用户快速开始项目并解决遇到的问题。此外，PyTorch 与许多研究项目和商业应用相结合，形成了一个强大的生态系统。
- 由于其灵活性和简便性，PyTorch 在学术界特别受欢迎，成为许多最新研究论文的首选框架。它支持快速实验的特点，使研究人员能够验证新想法并迅速实现原型。
- PyTorch 不仅易于使用，而且在性能方面也非常优秀。它可以无缝地运行在 CPU 和GPU 上，通过优化的C++库支持高效的内存使用和计算速度。
- PyTorch 提供了与其他重要科学计算库的接口，如NumPy和SciPy，以及可视化工具如TensorBoard。此外，它还支持ONNX（Open Neural Network Exchange）格式，这使得在不同框架之间转换模型变得更加容易。

本文研究将使用 PyTorch 框架微调 SMA 模型。在Python环境下，利用Pytorch库构建SAM大模型的基础框架。首先初始化模型结构，包括深度卷积网络、池化层、归一化层和全连接层，确保模型具备处理高维度数据的能力。紧接着，载入预训练的参数，以利用在其他大数据集上学到的特征。

## Transformer

Transformer是一种基于自注意力机制的神经网络架构，最初由Vaswani等人在2017年的论文《Attention Is All You Need》中提出。Transformer模型在自然语言处理（NLP）任务中取得了巨大成功，并被广泛应用于其他领域如计算机视觉（例如VIT， vision Transformer）。

### Transformer模型的组成

![Transformer 结构图]（./Transformer结构图.png）

图 2.3 Transformer 结构图

如图 2.3，Transformer模型主要由编码器（Encoder）和解码器（Decoder）两部分组成，每部分由多个相同的层（layers）堆叠而成。每个层主要包含两个子层（sublayers）：

#### 1. 编码器（Encoder）

每个编码器层包含以下两个子层：
- **自注意力层（Self-Attention Layer）**：计算输入序列中每个位置的注意力分数，捕捉输入序列中的全局依赖关系。
- **前馈神经网络（Feed-Forward Neural Network， FFN）**：对每个位置的输入进行独立的非线性变换。

每个编码器层的输出会通过残差连接（residual connection）和层归一化（layer normalization）后，传递给下一层。

#### 2. 解码器（Decoder）

每个解码器层包含三个子层：
- **自注意力层（Self-Attention Layer）**：与编码器相同，但只对解码器输入的前缀部分计算注意力分数。
- **编码器-解码器注意力层（Encoder-Decoder Attention Layer）**：将解码器的输入与编码器的输出结合，计算注意力分数，捕捉输入与输出之间的依赖关系。
- **前馈神经网络（Feed-Forward Neural Network， FFN）**：与编码器相同，对每个位置的输入进行独立的非线性变换。

同样，每个解码器层的输出也会通过残差连接和层归一化后，传递给下一层。

### 自注意力机制（Self-Attention Mechanism）

自注意力机制是Transformer的核心组件，它允许模型在计算每个位置的表示时，考虑整个序列中的其他位置。其工作原理如下：

1. **输入变换**：
    - 将输入序列（例如词嵌入）变换为查询（query）、键（key）和值（value）向量：
        $$
        Q = XW_Q， \quad K = XW_K， \quad V = XW_V
        $$
        其中，$W_Q$， $W_K$， $W_V$ 是学习到的权重矩阵。

2. **计算注意力分数**：
    - 计算查询与键的点积，并进行缩放和软最大化（softmax），得到注意力分数：
        $$
        \text{Attention}（Q， K， V） = \text{softmax}\left（\frac{QK^T}{\sqrt{d_k}}\right）V
        $$
        其中，$d_k$ 是键向量的维度。

3. **加权求和**：
    - 使用注意力分数对值向量进行加权求和，得到每个位置的新表示。

### 多头注意力机制（Multi-Head Attention）

为了捕捉不同子空间的信息，Transformer使用了多头注意力机制。具体做法是将查询、键、值向量分成多个头，每个头独立计算注意力，然后将结果拼接在一起，并通过线性变换得到最终的输出：
$$
\text{MultiHead}（Q， K， V） = \text{Concat}（\text{head}_1， \ldots， \text{head}_h）W_O
$$
其中，$\text{head}_i = \text{Attention}（QW_{Q_i}， KW_{K_i}， VW_{V_i}）$。

### 位置编码（Positional Encoding）

由于Transformer没有卷积或递归结构，它无法直接捕捉输入序列的位置信息。为此，Transformer在输入中添加了位置编码，提供位置信息。位置编码可以是固定的，也可以是可学习的，其形式通常为：
$$
\text{PE}_{（pos， 2i）} = \sin\left（\frac{pos}{10000^{2i/d}}\right）， \quad \text{PE}_{（pos， 2i+1）} = \cos\left（\frac{pos}{10000^{2i/d}}\right）
$$
其中，$pos$ 是位置，$i$ 是维度索引。

### 总结

Transformer通过自注意力机制和前馈神经网络，在自然语言处理和其他领域中实现了卓越的性能。其核心优势在于能够捕捉全局依赖关系，易于并行计算，并且具有良好的扩展性。自推出以来，Transformer模型已经衍生出许多变种和改进版本，并在许多任务中取得了显著成果。

## 分割大模型（SAM大模型）

本文主要研究通过对 SAM 大模型的微调训练，以适应在医学图像处理，尤其是对腹部 CT 扫描图像的肝脏肿瘤分割。

### 背景

SAM（Segment Anything Model）是近年来出现的一种新型深度学习模型，由 Meta 的 FAIR 实验室提出，旨在通过单一的模型实现对任何对象的高精度分割。SAM大模型通过大规模数据的预训练和针对特定任务的微调，实现了对不同对象类型的准确识别和分割。

SAM模型的强大之处在于它借鉴了自然语言处理领域的 Foundation Model。Foundation Model 在预训练阶段学习了大量的语言知识，从而能够在各种语言任务中表现出色。同样地，SAM模型在预训练阶段学习了大量的视觉知识，使其能够适应各种下游图像分割任务。

SAM模型的核心思想是使用提示学习来适应不同的分割问题。提示学习是一种通过给模型提供一些指导信息来帮助其完成任务的方法。在SAM模型中，研究者们设计了一种可提示的分割任务，使模型可以根据不同的任务需求进行微调。这种可提示的特性使得SAM模型能够轻松地适应各种复杂的分割问题，例如语义分割、实例分割等。

为了实现强大的零样本学习能力，SAM模型在预训练阶段使用了大规模的数据集进行训练。通过在大量图像数据上的学习，模型能够提取出通用的视觉特征，从而在面对新的、未见过的图像时，能够快速地进行有效地分割。这种零样本学习能力使得SAM模型在处理新场景、新任务时具有很大的优势，例如将其微调，用于肝脏肿瘤分割软件的开发[@wuMedicalSAMAdapter]。

在网络数据集上预训练的大语言模型具有强大的 zero-shot（零样本）和 few-shot（少样本）的泛化能力，这些“基础模型”可以推广到超出训练过程中的任务和数据分布，这种能力通过“prompt engineering”实现，具体就是输入提示语得到有效的文本输出，使用网络上的大量文本资料库进行缩放和训练后，可以看出这种零样本和少样本的训练的模型比专一性质功能模型效果还要好。数据集越大，效果越明显。

视觉任务方面也对这种基础模型进行了探索，比如CLIP和ALIGN利用对比学习，将文本和图像编码进行了对齐，通过提示语生成image encoder，就可以扩展到下游任务，比如生成图像[@kirillovSegmentAnything2023]。

SAM通常在自然图像上表现优异，但是在特定领域如医疗影响，遥感图像等，由于训练数据集缺乏这些数据，SAM 的效果并不是理想。因此，在特定数据集上微调 SAM 是十分有必要的。

### SAM 模型结构

如图 2.4 所示SAM模型结构主要包括以下几个部分[@kirillovSegmentAnything2023]：

1. 图像编码器（Image Encoder）：
- 接收输入图像并提取图像特征。
- 通常使用预训练的视觉模型，如VIT（vision Transformer）。

2. 提示编码器（Prompt Encoder）：
- 处理用户提供的提示信息（如点、框、文本等）。
- 提取提示信息的特征表示。

3. 掩码解码器（Mask Decoder）：
- 将图像特征和提示特征进行融合。
- 生成分割掩码。

4. 特征融合与加权（Feature Fusion and Weighting）：
- 通过逐元素相乘（element-wise multiplication）对图像特征进行加权。
- 利用提示特征对图像特征进行调整，提升分割精度。

5. 最终输出：
- 生成图像的分割掩码。

![SAM 模型的结构]（SAM结构图.png）

图 2.4 SAM 模型的结构

#### SAM 模型运行步骤

- 输入图像（Image）：模型接收一幅输入图像。
- 图像编码器（Image Encoder）：输入图像经过图像编码器（通常是VIT），提取出高维度的图像特征。
- 提示编码器（Prompt Encoder）：用户提供的提示信息（如标记点、框等）经过提示编码器，提取出提示特征。
- 特征融合与加权（Feature Fusion and Weighting）：图像特征和提示特征进行融合。具体操作是通过逐元素相乘（element-wise multiplication），使提示特征对图像特征进行加权。
- 掩码解码器（Mask Decoder）：融合后的特征通过掩码解码器，生成图像的分割掩码。
- 最终输出（Final Output）：输出最终的分割掩码，表示图像中的分割区域。

#### 图像编码器（Image Encoder）

利用mae预训练的初始点（VIT），最低限度适应高分辨率的输入，该编码器在提示编码器（prompt encoder）之前，对每张图像只运行一次。

输入（c，h，w）的图像，对图像进行缩放，按照长边缩放成1024，短边不够就pad，得到（c，1024，1024）的图像，经过图像编码器（image encoder）处理，得到对图像16倍下采样的特征（feature），大小为（256，64，64）。

#### 提示编码器（Prompt Encoder）

提示编码器分成2类：稀疏的（点，box，文本），稠密的（mask）。

- 点（point）:映射到256维的向量，包含代表点位置的位置编码（positional encoding），加 2 个代表该点是前景/背景的可学习的嵌入（embedding）。
- 框（box）:用一个嵌入对表示（1）可学习的嵌入代表左上角（2）可学习的嵌入代表右下角
- 文本：通过CLIP模型进行文本编码。
- 掩码（mask）:用输入图像 $1/4$ 分辨率的掩码，然后用 （2，2） 卷积核步长为 2，输出通道数为4和16，再用 （1，1） 卷积核将通道数量升到256。掩码和图像嵌入（iamge embedding）通过逐元素相乘（element-wise），也就是说用掩码的特征对图像的特征进行加权使特定区域被放大或抑制。

## 本章小结

本章探讨讲述了计算机断层图像扫描扫描（Computed Tomography， CT）、深度学习的基本原理、PyTorch 框架的特点，以及 Transformer 和 SAM（Segment Anything Model）模型的结构与机制。深度学习通过多层神经网络模拟人脑处理数据的方式，从输入层接收数据，经隐藏层处理后，在输出层产生结果。其关键在于使用损失函数评估预测误差，并通过反向传播和梯度下降等优化算法调整网络参数，以减少误差。PyTorch 是一个开源的机器学习库，以动态计算图和易用的 API 著称，广泛应用于计算机视觉和自然语言处理领域。Transformer 是一种基于自注意力机制的神经网络架构，通过编码器和解码器捕捉输入序列的全局依赖关系，易于并行计算且具有良好的扩展性。SAM 模型由 Meta 的 FAIR 实验室提出，旨在通过单一模型实现高精度分割。它通过大规模数据预训练和提示学习，适应各种下游图像分割任务。其结构包括图像编码器、提示编码器、特征融合与加权、掩码解码器和最终输出部分，通过对图像特征和提示特征的融合与加权，生成高精度分割掩码。这些技术和模型展示了深度学习在图像处理领域的强大性能和应用前景，为后续研究奠定了基础。

# 实验研究

## 准备数据集

研究使用 3Dircadb1 数据集进行训练、验证和测试。数据集共包括 20 个病例的 CT 图像，每个图像都附有肝脏肿瘤的掩码（如表1），便于对数据集的训练与测试。对数据集进行随机分组，80% 作为训练集，10% 作为验证集，10% 作为测试集。在腹部 CT 图像中，肝脏和相邻的组织器官呈现紧贴的状态，并且它们之间的边界不清晰以及对比度较低，所以 CT 图像在输入到模型之前需要对其进行一些处理，减少无关噪声的干扰，增强图像的对比度。除上述处理操作外，数据集还进行了旋转、平移以及缩放，以此提升模型的泛化能力和鲁棒性，避免过拟合情况的发生。


表 3.1 数据集内容

| 文件名            | 文件内容                                      |     |
| -------------- | ----------------------------------------- | --- |
| PATIENT_DICOM  | DICOM 格式的匿名患者图像                           |     |
| LABELLED_DICOM | DICOM 格式分割的各个感兴趣区域对应的标签图像                 |     |
| MASKS_DICOM    | 包含每个 mask 的 DICOM 图像的各个感兴趣区域的名称对应的一组新子文件夹 |     |

**读取数据**：从原始的 DICOM 格式文件中读取数据，并转换成数组格式以便于处理。

**数据预处理**

- **CT** **值转换**：将CT图像的原始值转换为 Hounsfield Units （HU），以标准化不同设备和协议下的图像数据。
- **窗口化**：应用窗口化技术以增强图像中特定组织或结构的可视化。
- **直方图均衡化**：使用CLAHE方法改善图像的对比度，特别是对于医学图像中经常存在的低对比度区域。
- **归一化**：将图像数据缩放到 \[0， 1\] 区间，以便于网络处理。
- **目标区域提取**：只保留包含肝脏的腹部切片，排除其他不相关的图像。

**数据增强**

- **定义增强参数**：设置旋转、平移、剪切和缩放等增强操作的参数。
- **应用数据增强**：对图像和掩码（mask）应用相同的变换，以增加数据集的多样性并提高模型的泛化能力。

**数据存储**

- **HDF5** **格式**：将处理后的数据存储为 HDF5 格式，以减少 I/O 操作并方便数据共享。
- **自定义类**：使用 HDF5DatasetWriter 和 HDF5DatasetGenerator 类来管理数据的读写操作。

## 实验过程

SAM 分为图像编码器（image encoder）、提示编码器（prompt encoder）和掩码解码器（mask decoder） 3 部分。图像编码器使用了掩码自编码器（masked autoencoders，MAE）方法预训练的VIT（Vision Transformer）模型。MAE 是一种自监督学习方法，能够将输入的图片分块，并随机进行遮盖，之后借助编码器和解码器重构这些被遮盖的像素。VIT 模型是 Transformer 模型在 CV 领域的应用，用于把图像映射到特征空间，具体结构如图４所示。将图片输入图像编码器后，首先使用卷积分块缩小尺寸，之后借助 Flatten 函数将分块的图像转换成向量，并与位置信息（position embedding）相加，相加结果经过 Transformer Encoder 处理生成特征图，最后再通过两层卷积对特征图进行降维，得到图像嵌入（Image Bedding）。位置信息是初始为 0 的参数矩阵，用于后续位置更新。

<!-- SAM 默认的输入尺寸为$1024×1024$像素，本文试验数据集图像为$512×512$像素，若直接输入默认图像编码器后会存在大量无意义的填充，为提高模型效率将 Transformer Encoder 调整为 8 个 Transformer Block，其中 6 个应用局部注意力机制，剩余 2 个为全局注意力机制。内部的 Transformer Block 由一个注意力机制模块和多个全连接层组成。 -->

![VIT]（VIT结构图.png）

图 3.1 VIT 结构图

### 加载预训练模型

加载 meta 预训练的 SAM 模型作为基础模型。加载预训练模型的权重，并设置为微调模式。为了保留预训练模型中已经学习到的有用特征，通常会冻结模型的输入层，只微调模型的顶部层。这可以通过设置模型中某些层的参数不可训练为“True”来实现。冻结输入层可以防止在训练过程中更新这些层的权重，从而保留原始模型的特征表示。只微调顶部层有助于模型适应新任务的特定需求，同时减少训练时间和计算资源。

### 训练模型并监控性能

使用训练数据集进行迭代训练。在训练过程中，需要监控模型的性能指标，如图 3.2 中模型训练输出训练损失和验证损失。为了确保模型的泛化能力，可以在每个训练周期结束后使用验证集进行评估。通过细致地微调，提升模型对肝脏肿瘤图像特点的学习能力和分割准确性。

![性能监控]（模型训练输出.png）

图 3.2 模型训练性能监控

1.     模型架构调整

自定义Prompt Encoder: 为了更好地适应肝脏CT图像特征，可以设计或调整Prompt Encoder部分，增加对解剖结构敏感的特征提取层。

Mask Decoder微调: 在Mask Decoder部分，保持原有Transformer架构的基础上，微调最后几层的权重，使其对肝脏和肿瘤边缘更加敏感。

多尺度特征融合: 引入多尺度特征融合策略，如U-Net结构中的跳跃连接，结合不同层级的特征来提高分割精度。

2. 损失函数设计

Dice Loss + BCE Loss: 使用结合了Dice Loss和二元交叉熵损失（BCE）的复合损失函数，Dice Loss关注区域的重叠程度，BCE则强调分类的准确性。

加权损失: 对肿瘤区域施加更高的权重，因为肿瘤区域相对于正常肝脏组织更为关键，且数量较少，这样可以平衡类别不均衡问题。

3. 训练策略

迁移学习: 从预训练的SAM模型开始，冻结部分或全部编码器层，仅微调解码器层和可能新增的自定义层。

学习率调度：使用余弦退火学习率调度（Cosine Annealing），初始学习率设为$1^{-4}$，随着训练进行逐渐降低。

   - 学习率在训练过程中按照余弦函数变化，使得学习率在训练初期较高，逐渐减小到最小值，然后再次升高。
   - 公式：$$\text{lr}_t = \text{lr}_{\min} + \frac{1}{2} （\text{lr}_0 - \text{lr}_{\min}） （1 + \cos（\frac{T_{\text{cur}}}{T_{\text{max}}} \pi））$$
	其中，$text{lr}_t$为第$t$个训练周期（epoch）的学习率，$\text{lr}_0$为初始学习率，$\text{lr}_{\min}$为最小学习率，$T_{\text{cur}}$为当前训练周期（epoch），$T_{\text{max}}$为总的训练周期（epoch）数。
   

混合精度训练: 利用混合精度训练加速训练过程并节省 GPU 内存，例如使用 NVIDIA 的 Apex 库。

数据增强: 实施旋转、翻转、缩放、剪切、亮度变化等数据增强操作，并利用 RandAugment 等自动化增强策略增加多样性。

4. 验证与评估

交叉验证: 使用K折交叉验证（如5折）来更稳健地评估模型性能，避免过拟合。

性能指标: 主要评估指标包括 Dice 相似系数（Dice Score）、Jaccard Index、Hausdorff距离、敏感性（Sensitivity）、特异性（Specificity）等。

5. 模型优化与后处理

模型融合: 如果资源允许，可以训练多个模型，并采用模型融合策略提高最终分割的准确性。

后处理算法: 应用形态学操作（如开运算、闭运算）平滑分割边界，去除小孤立区域，或使用条件随机场（CRF）后处理提高边界界定质量。

## 实验结果

在搭建好的 SAM 大模型上实施肝脏肿瘤的分割任务，使用常见性能指标，准确度（Accuracy）、Dice 系数评价模型性能。通过这些指标，量化分析模型的分割效果，评估模型的训练效果并与其他分割方案比较。

## 本章小结

探讨了使用SAM大模型进行肝脏肿瘤分割的整个训练和微调过程，以及软件开发的关键步骤。首先，我们通过安装和配置必要的环境和库，为SAM模型的部署和训练奠定了基础。接着，创建了详细的配置文件，指定了模型训练的关键参数，包括冻结的网络层、学习率、优化器配置和训练周期等。

通过实际数据集的训练，模型经历了从初始化到连续迭代过程，每个训练周期都细致地调整了模型的权重，以适应复杂的肝脏肿瘤图像特征。在训练过程中，我们使用了多种损失函数，这些都是为了优化模型在分割任务上的表现并减少预测误差。

最终，模型的性能通过多个标准评估指标进行了量化，包括准确度、Dice 系数，这些指标帮助我们客观评价了模型在实际肝脏肿瘤分割任务中的效能。此外，通过结果的可视化分析，我们能够直观地看到模型在处理真实图像数据时的表现，包括成功案例和需要改进的地方。

# 结果分析与性能比较

为了全面评估基于 SAM 大模型的肝脏肿瘤分割软件的性能，选取主流的分割模型 U-Net 作为比较对象，U-Net 在医学图像分割领域内已有大量成功应用，与之比较，可以更好的评估模型能力。

通过实际的实验数据，本研究采用了以下性能评价指标：

## 评价指标

### Dice 系数

**定义**：Dice 系数（也称为 Dice 相似系数）是一种用于衡量两个样本集合相似度的统计指标，尤其适用于评估图像分割的精度。

**计算方法**：
$$ \text{Dice} = \frac{2TP}{2TP + FP + FN} = \frac{2|A \cap B|}{|A| + |B|} $$

- $TP$ （True Positive）：真正例数，即正确预测为正类的像素数。
- $TN$（True Negative）：真负例数，即正确预测为负类的像素数。
- $FP$（False Positive）：假正例数，即错误预测为正类的像素数。
- $FN$（False Negative）：假负例数，即错误预测为负类的像素数。
- $A$ 为预测的二值掩码。
- $B$ 为真实的二值掩码。
- $|A \cap B|$ 为预测与真实掩码的交集像素数。

**优点**：Dice 系数在处理类别不平衡的数据集时表现优异。它在较小的目标（如肿瘤）分割中，能够更好地反映模型的实际性能。

**缺点**：Dice 系数相对复杂，计算需要同时考虑预测结果与真实标签，尤其在处理多类别分割任务时，需要分别计算每个类别的 Dice 系数，再求平均值。

### 二值交叉熵损失（BCE Loss）

#### 定义
二值交叉熵损失（Binary Cross-Entropy Loss）用于二分类任务，衡量模型预测值与真实值之间的差异。

#### 公式
对于每个像素的二值交叉熵损失定义如下：
$$\text{BCE}(p, g) = - \left( g \log(p) + (1 - g) \log(1 - p) \right)$$
其中，$p$ 是预测值，$g$ 是真实值。

整个图像的 BCE Loss 同样需要通过对所有像素的 BCE 损失求平均得到：
$$\text{BCE Loss} = \frac{1}{N} \sum_{i=1}^{N} \text{BCE}(p_i, g_i)$$
其中，$N$ 是图像中的总像素数。

BCE Loss 适用于二分类问题，常用于分割任务中的每个像素分类（如前景和背景的分类）。

### 交并比（IOU）

#### 定义
交并比（Intersection Over Union, IOU）也称为 Jaccard Index，是一种常用的评估指标，用于衡量预测分割与真实分割之间的重叠程度。用于衡量预测分割结果与真实标注之间的一致性。IOU的计算公式表示如下：

$$\text{IoU}(A, B) = \frac{|A \cap B|}{|A \cup B|} = \frac{\sum_{i} p_i g_i}{\sum_{i} p_i + \sum_{i} g_i - \sum_{i} p_i g_i}$$

其中，$p$ 是预测值，$g$ 是真实值。

IOU 通常用作评估指标，而不是损失函数。它用于衡量分割结果与真实标签的重叠程度，广泛应用于各种分割任务的性能评估。

## 评估模型性能

以上介绍的评估指标中，DICE 系数与 DCE 结合作为模型训练中的损失函数使用，交并比（IOU）用于评估模型性能。交并比（IOU）反映了预测掩码与真实掩码之间的重叠程度，是一个介于0到1之间的值。IOU值越高，表示预测的分割结果与真实标注的一致性越好，通常用于评估分割算法的性能，尤其是在语义分割和实例分割任务中。

表1 显示了不同模型在测试集上的分割性能比较，结果表明，我们提出的基于 SAM 的分割方法在所有指标上均优于传统方法和 U-net 模型深度学习方法。

表 模型分割性能比较（标题5）

| 模型       | SAM   | RAVD  | ASSD  | HD    |
| -------- | ----- | ----- | ----- | ----- |
| IOU（交并比） | 0.948 | 12.1% | 1.9mm | 9.3mm |


##### 可视化结果

图1展示了不同模型在肝脏肿瘤分割任务中的可视化结果。红色轮廓表示真实标注，绿色轮廓表示模型预测结果。可以看出，SAM 模型能够更准确地捕捉肝脏肿瘤的边界，并且在处理复杂形状和模糊边界时表现出色。

![分割结果演示]（分割结果演示.png）

图 4.1 分割结果演示，从左到右依次为原 CT 图像、肿瘤标签、分割结果


性能对比分析侧重于考察SAM大模型与其他模型在精确度、Dice 系数方面的差异，同时评价模型的计算效率。分析结果指出，模型训练效果良好，SAM 模型在精度上具有优势，尤其在小肿瘤区域的分割上显示出更高的敏感性。

# 结论


本研究通过开发基于SAM大模型的肝脏肿瘤分割软件，展示了深度学习在医学图像分割领域的强大潜力。SAM大模型的引入，提高了分割精确度，尤其在处理腹部CT图像中肝脏肿瘤的复杂情况时表现出显著的优势。通过与其他流行模型的性能对比，本研究不仅证明了SAM大模型在肝脏肿瘤分割任务上的有效性，也为未来在此类应用中深度学习模型的优化提供了有价值的参考。

进一步的分析和实验结果表明，虽然基于 SAM 大模型的分割软件在准确度上取得了优异的成绩，但仍存在计算效率和模型泛化能力方面的挑战。未来的工作可以着重于这些方面，探索更高效的算法或技术来提升模型性能，从而更好地服务于临床诊断和治疗规划。

尽管 SAM 在肝脏肿瘤分割上显示出前景，但仍需针对医学图像的特点进行进一步优化和调整。未来的研究可以探索如何结合医学专家的知识和SAM的自动学习能力，以提高分割精度，减少需要手动调整的工作。同时，开发面向特定如肝脏肿瘤的深度学习模型，将是推动医学图像处理技术发展的关键。

综上所述，基于 SAM 模型的肝脏肿瘤分割软件的开发，不仅可以改善现有的图像分割方法，还有助于提高肝脏疾病的诊断效率和准确性。未来的研究应当着重于模型的实际应用和临床转化，以实现医学影像自动化分析的最终目标。

## 不足

1. **数据集局限性**：
    本研究所使用的数据集可能存在样本量不足或样本分布不均的问题，这可能导致模型在某些特定场景下的泛化能力受限。未来的研究可以通过引入更多样本量、更丰富的数据集，以及涵盖更多不同类型的肝脏肿瘤图像来解决这一问题。

2. **模型复杂性和计算资源需求**：
    由于 SAM 模型及其微调过程中涉及复杂的神经网络结构和大量的计算资源，训练和推理的时间和成本较高。在训练过程中冻结了模型的大部分内容，这在实际应用中可能限制其能力发挥。未来可以尝试通过模型压缩、剪枝和量化等技术来减少计算资源需求。

3. **实际应用验证不足**：
    虽然本研究在测试集上展示了良好的性能，但在实际临床应用中的验证和评估尚不足。未来需要在真实临床环境中进行更多的测试和验证，以确保模型在实际应用中的可靠性和有效性。

## 展望

1. **多模态数据融合**：
    未来的研究可以探索将不同模态的医学图像（如MRI、CT、超声图像）进行融合，以提升模型的鲁棒性和准确性。多模态数据的融合可以提供更多的病灶信息，有助于更准确的肝脏肿瘤分割。

2. **模型的迁移学习与领域自适应**：
    可以尝试将本研究的方法迁移到其他类型的医学图像分割任务中，如肺部、脑部等其他器官的肿瘤分割。同时，引入领域自适应技术，使模型能够在不同医院或不同设备生成的图像数据上保持高性能。

3. **实时分割与嵌入式应用**：
    未来可以探索如何将微调后的SAM模型部署到嵌入式设备或实时系统中，以便在临床实践中实现实时的肝脏肿瘤分割。这需要在模型压缩和加速方面进行深入研究。

4. **集成学习与模型融合**：
    可以尝试将SAM模型与其他先进的图像分割模型进行集成，利用集成学习的优势，进一步提升分割效果。模型融合技术可以综合多种模型的优点，提高最终分割结果的准确性和稳定性。

5. **临床合作与反馈**：
    加强与临床专家的合作，通过他们的反馈不断改进和优化模型。这不仅有助于提升模型的实际应用价值，还能确保研究方向和临床需求紧密结合。

### 总结

尽管本研究在利用 SAM 模型进行肝脏肿瘤分割方面取得了显著成果，但仍存在一些不足和挑战。未来的研究可以通过多模态数据融合、迁移学习、实时分割、集成学习和临床合作等多方面的努力，进一步提升模型性能，扩大其应用范围，最终实现更高效、更准确的医学图像分割系统。

在基于 SAM 大模型的肝脏肿瘤分割软件开发上取得了很好的成效，将来可通过对模型的进一步优化微调与前端开发提升其性能与易用性。我希望在以后的学习中能在该研究方面继续不懈学习和研究，也希望能通过自己的努力能够为医疗领域图像处理奉献力量。

# 参考文献

# 致谢

在本科毕业论文的撰写过程中，得到了许多人的帮助和支持。在此，我衷心感谢他们每一个人。首先，我要特别感谢我的导师刘琨，在学术上给予我无限的指导。刘琨老师严谨的学术态度、深厚的专业知识和无私的精神深深影响了我。在论文的选题、研究以及写作过程中，刘琨老师都给予我悉心指导，每一次讨论都让我受益匪浅。感谢测控专业的所有老师和同学们，在我的大学生活中给予我帮助和支持。特别是实验室的同学们，我们共同度过了许多难忘的时光，彼此间的讨论和合作使我受益良多。此外，我还要感谢我的家人对我的支持和鼓励。父母始终是我最坚强的后盾，他们的理解和爱让我在遇到困难和挫折时永不放弃。感谢他们无条件的爱和对我的信任，是他们让我有勇气追求自己的梦想。最后，感谢所有曾经给予我帮助和启发的人。是你们的帮助和支持使我能够顺利完成我的学业。
